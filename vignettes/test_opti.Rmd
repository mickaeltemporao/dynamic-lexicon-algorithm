---
title: "Test optimisation combinatoire"
author: "FREDON Louis"
date: "24/06/2021"
output: html_document
---

```{r setup, include=FALSE}
```

## Résumé de l'idée d'algorithme

Dans ce document nous allons essayer de mettre au point un algorithme qui va aller trouver un meilleur sous ensemble de données capable de prédire au mieux notre target (idéologie, age, sexe ..)

Nous avons déjà implémenter dans le package une fonction nommée algo_10 qui fait 10 sample aléatoire de vecteurs d'utilisateurs et sort le meilleur subset avec le meilleur score de prédiction.

Pour "battre" cette algorithme nous allons nous baser sur l'optimisation combinatoire.

Nous allons effectuer des combinaisons des meilleurs sous-ensemble de vecteurs pour arriver à de meilleurs résultats.

## Motivation


Pour effectuer cela, on se base sur l'hypothèse que la combinaison aléatoires des meilleurs subset donne de meilleurs score.

En termes mathématiques, on va essayer d'extraire les meilleures combinaisons de sous ensmeble.

## Démarche

Notre première idée est de prendre les 3 meilleurs subset de la sortie de la fonction algo_10 et de faire toutes les combinaisons de tailles 10 de ces 3 vecteurs.

Mathématiquement on va chercher les 10 parmi 30 meilleures combinaisons.

Ensuite nous allons prendre 50 de ces combinaisons aléatoires.

Effcetuons cet algorihtme :

```{r}
library(DLA)


```

Prenons les 3 meilleurs subset sortant de la fonction algo_10 et on les implemente dans un vecteur:

```{r,eval=FALSE}
calib_vector_opti<-q[1:3,2:11] # on prends les 3 meilleurs subset

calib_vector_opti<-c(calib_vector_opti[1,],calib_vector_opti[2,],calib_vector_opti[3,])# on les vectorise
calib_vector_opti<-as.numeric(calib_vector_opti)
```


On peut maintenant calculer les combinaisons de ces vecteurs de taille 10 :

```{r,eval=FALSE}
combin<-combn(calib_vector_opti,10)# on calcule les combinaisons de 10 nombres
```
 
On fait un sample aléatoire de 50 :

```{r,eval=FALSE}

calib_vector_opti<-combin[,sample.int(n=dim(combin)[2],size=50)]# on fait un sample de 50 aléatoires

calib_vector_opti<-t(calib_vector_opti)
calib_vector_opti<-as.data.frame(calib_vector_opti)

```

Maintenant que nous avons nos 50 combinaisons on va calibrer notre sous espace sur ces vecteurs et regarder si le score est meilleur que la fonction algo_10 :

```{r,eval=FALSE}
### on test comme précédement

a <- seq(1,50)
data_cor1 <- data.frame(a)
colnames(data_cor1)[1] <- "numéro du sample"
remove(a)


for (i in 1:50){


  X1<-calib_vector_opti[i,]
  X1<-as.numeric(X1)

  for(j in 1:length(X1)){
    data_cor1[i,j+1]<-X1[j]
    colnames(data_cor1)[j+1]<-paste0("donnée de calib",j)
  }


  x <- calibrate(dfm_fixture,complet=T,X1)


  #use weight on the other

  y <- use_weight(x[[2]],rownames(x[[1]]),x[[1]])


  ## Data frame des opinions de tous

  library(dplyr)
  require(rpart)
  opinions_df <- rbind(x[[3]], y[[1]])
  opinions_df$users <- as.numeric(opinions_df$users)
  opinions_df$opinions <- as.numeric(opinions_df$opinions)


  ###Validation

  opinions_df_arrange <- arrange(opinions_df,users)

  df_validation_arrange <- arrange(df_validation,users_id)

  op_match <- merge(opinions_df_arrange,df_validation_arrange,by.x = "users",by.y = "users_id")


  validation_metrics <- cor(op_match$opinions,op_match[,3])


  data_cor1[i,length(X1)+2] <- validation_metrics
  colnames(data_cor1)[length(X1)+2] <- "validation_score"

  data_cor1[i,length(X1)+3] <- x2y(op_match$opinions,op_match[,3])[2]
  colnames(data_cor1)[length(X1)+3] <- "validation_score_x2y"

}

data_cor1<-arrange(data_cor1,data_cor1$validation_score) # notre tableau des scores de ces 50 vecteurs
```

```{r}
data_cor1
```



## Résultats

Les résultats sont dans le tableau data_cor1.

Pour plus de visibilité nous allons tracer le graph des scores comparés à la limite atteint par le meilleur vecteur de calibration théorique trouvé par la fixture et le meilleur score que l'algo_10 nous retourne :

```{r}
library(ggplot2)
library(gridExtra)



co<-ggplot(data_cor1,aes(x =`numéro du sample`, y = abs(validation_score))) +geom_line()+geom_point()
co<-co+geom_hline(aes(yintercept=abs(q$validation_score[1]),linetype = "algo_10 score"), 
                color = "blue", size=0.5)+
  geom_hline(aes(yintercept=abs(validation_score_fixture_weighted), linetype = "best score"), 
                color = "green", size=0.5) +
    scale_linetype_manual(name = "limit", values = c(2, 2), guide = guide_legend(override.aes = list(color = c("blue", "green"))))


co
co

```


## Discussion


On remarque que cet algorithme arrive à dépasser significativement le score de algo_10 sur quelques vecteur cependant la plupart sont en dessous des deux scores.

Il est plutôt rapide, il donne quelques meilleurs résultats mais n'est pas très performant.















