---
title: "Test optimisation combinatoire"
author: "FREDON Louis"
date: "24/06/2021"
output: html_document
---

```{r setup, include=FALSE}
```

## Premier idée d'algorithme

Dans ce document nous allons essayer de mettre au point un algorithme qui va aller trouver un meilleur sous ensemble de données capable de prédire au mieux notre target (idéologie, age, sexe ..)

Nous avons déjà implémenter dans le package une fonction nommée algo_10 qui fait 10 sample aléatoire de vecteurs d'utilisateurs et sort le meilleur subset avec le meilleur score de prédiction.

Pour "battre" cette algorithme nous allons nous baser sur l'optimisation combinatoire.

On se base sur l'hypothèse que la combinaison des meilleurs subset donne de meilleurs score.

Notre première idée est de prendre les 3 meilleurs subset de la sortie de la fonction algo_10 et de faire toutes les combinaisons de 10 nombres de ces 3 vecteurs.

Pour ensuite prendre 50 combinaisons aléatoires.

Chargeons l'environnement avec nos résultats pour éviter de les relancer (ce qui peut être long et fastidieux):

```{r}
library(DLA)
data(package = "DLA")

```

Maintenant prenons les 3 meilleurs subset sortant de la fonction algo_10 et on les implemente dans un vecteur:

```{r,eval=FALSE}
calib_vector_opti<-q[1:3,2:11] # on prends les 3 meilleurs subset

calib_vector_opti<-c(calib_vector_opti[1,],calib_vector_opti[2,],calib_vector_opti[3,])# on les vectorise
calib_vector_opti<-as.numeric(calib_vector_opti)
```


On peut maintenant calculer les combinaisons de ces vecteurs de taille 10 :

```{r,eval=FALSE}
combin<-combn(calib_vector_opti,10)# on calcule les combinaisons de 10 nombres
```
 
On fait un sample aléatoire de 50 :

```{r,eval=FALSE}

calib_vector_opti<-combin[,sample.int(n=dim(combin)[2],size=50)]# on fait un sample de 50 aléatoires

calib_vector_opti<-t(calib_vector_opti)
calib_vector_opti<-as.data.frame(calib_vector_opti)

```

Maintenant que nous aons nos 50 combinaisons on va calibrer notre sous espace sur ces vecteurs et regarder si le score est meilleur que la fonction algo_10 :

```{r,eval=FALSE}
### on test comme précédement

a <- seq(1,50)
data_cor1 <- data.frame(a)
colnames(data_cor1)[1] <- "numéro du sample"
remove(a)


for (i in 1:50){


  X1<-calib_vector_opti[i,]
  X1<-as.numeric(X1)

  for(j in 1:length(X1)){
    data_cor1[i,j+1]<-X1[j]
    colnames(data_cor1)[j+1]<-paste0("donnée de calib",j)
  }


  x <- calibrate(dfm_fixture,complet=T,X1)


  #use weight on the other

  y <- use_weight(x[[2]],rownames(x[[1]]),x[[1]])


  ## Data frame des opinions de tous

  library(dplyr)
  require(rpart)
  opinions_df <- rbind(x[[3]], y[[1]])
  opinions_df$users <- as.numeric(opinions_df$users)
  opinions_df$opinions <- as.numeric(opinions_df$opinions)


  ###Validation

  opinions_df_arrange <- arrange(opinions_df,users)

  df_validation_arrange <- arrange(df_validation,users_id)

  op_match <- merge(opinions_df_arrange,df_validation_arrange,by.x = "users",by.y = "users_id")


  validation_metrics <- cor(op_match$opinions,op_match[,3])


  data_cor1[i,length(X1)+2] <- validation_metrics
  colnames(data_cor1)[length(X1)+2] <- "validation_score"

  data_cor1[i,length(X1)+3] <- x2y(op_match$opinions,op_match[,3])[2]
  colnames(data_cor1)[length(X1)+3] <- "validation_score_x2y"

}

data_cor1<-arrange(data_cor1,data_cor1$validation_score) # notre tableau des scores de ces 50 vecteurs
```

```{r}
data_cor1
```

Les résultats sont dans le tableau data_cor1. 

On peut plot ces résultats et les comparer au meilleur score de algo_10 :

```{r}
library(ggplot2)
library(gridExtra)



co<-ggplot(data_cor1,aes(x =`numéro du sample`, y = abs(validation_score))) +geom_line()+geom_point()
co<-co+geom_hline(yintercept=abs(q$validation_score[1]), 
                color = "blue", size=0.5)
co

```

On remarque que cet algorithme arrive à dépasser significativement le score de algo_10.

De plus il demeure plutôt rapide.













