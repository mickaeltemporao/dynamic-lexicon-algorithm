---
title: "Optimisation de la fonction algo_10"
author: "FREDON Louis"
date: "30/06/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## Résumé/ Motivation de  l'optimisation de l'algorithme algo_10

```{r}
library(DLA)
```

Au vue des résultats de performance des tests réalisés nous décidons de garder l'algortihme 3 qui demeure être le plus performant.

Cependant, si le nombres d'utilisateurs augmente, et que donc la taille des combinaisons augment également, l'algorithme risque d'être très lent et de donner des résultats très tardivement.

C'est pourquoi dans ce document nous allons essayer d'améliorer celui-ci afin de le rendre tout aussi performant ( si possible) mais surtout, beaucoup plus rapide.



## Démarche

Pour cela, au lieu de trier le vecteur de calibration en allant chercher et piocher dans tout le reste disponible, nous allons uniquement aller piocher dans un sous ensemble disponible.

Cela va donc diviser la taille de la boucle et par conséquent la durée de l'algorithme.


Comme l'algorithme 3, on commence par récupérer le meilleurs subset retourné de la fonction algo_10 :

```{r, eval = FALSE}
calib_vector_opti2<-q[1,2:11]
calib_vector_opti2<-as.numeric(calib_vector_opti2)

X3<-as.numeric(rownames(dfm_fixture))[-calib_vector_opti2]

```


On garde la fonction qui permets de remplacer les chiffres du vecteur à l'indice voulu :


```{r, eval = FALSE}
# On crée une fonction qui change le chiffre du vecteur de l'indice voulu

insert <- function(x, index, replacement, how = c("replace","left","right")) {
how <- match.arg(how)
repl <- switch (how,
replace = replacement,
left = Map("c", index, replacement),
right = Map("c", replacement, index)
)
x[index] <- repl
unlist(x)
}
```


Maintenant nous allons devoir trouver la taille du vecteur à prendre, pour cela nous allons tester plusieurs taille et comparer la performance et la durée.

Prenons plusieurs taille différente :

```{r, eval =FALSE}
taille<-c(0.1*length(X3),0.2*length(X3),0.3*length(X3),0.4*length(X3),0.5*length(X3))
```


On peut parcourir maintenant toutes les tailles et regarder laquelle nous allons garder :

Et on peut maintenant lancer l'algorithme :

```{r,eval=FALSE}

for (k in taille){
  start_time=Sys.time
X3_opti<- sample(X3,size = k)

a <- seq(1,252)
data_cor3_opti <- data.frame(a)
colnames(data_cor3_opti)[1] <- "results"
remove(a)



niter<-0

for(j in 1){
  for(i in X3_opti){
  
  X_replace<-as.numeric(insert(calib_vector_opti2,j,i))


  x <- calibrate(dfm_fixture,complet=T,X_replace)


  #use weight on the other

  y <- use_weight(x[[2]],rownames(x[[1]]),x[[1]])


  ## Data frame des opinions de tous

  library(dplyr)
  require(rpart)
  opinions_df <- rbind(x[[3]], y[[1]])
  opinions_df$users <- as.numeric(opinions_df$users)
  opinions_df$opinions <- as.numeric(opinions_df$opinions)


  ###Validation

  opinions_df_arrange <- arrange(opinions_df,users)

  df_validation_arrange <- arrange(df_validation,users_id)

  op_match <- merge(opinions_df_arrange,df_validation_arrange,by.x = "users",by.y = "users_id")


  validation_metrics <- cor(op_match$opinions,op_match[,3])

  
  if((validation_metrics>abs(validation_score_fixture_weighted))){ # si le score est meilleur alors on garde et on passe a l'indice suivant 
    niter<-niter+1
    for(w in 1:length(X_replace)){
    data_cor3_opti[niter,w]<-X_replace[w]
    colnames(data_cor3_opti)[w]<-paste0("donnée de calib",w)
    }
    data_cor3_opti[niter,length(X_replace)+1]<-validation_metrics
    colnames(data_cor3_opti)[length(X_replace)+1]<-"score"
        data_cor3_opti[niter,length(X_replace)+2]<-end_time - start_time
    colnames(data_opt)[niter,length(X_replace)+2]<-"time of running"
    break
   
  }
  }
}
  
  for(j in 2:10){
  for(i in X3_opti){
  
  X_replace<-as.numeric(insert(calib_vector_opti2,j,i))


  x <- calibrate(dfm_fixture,complet=T,X_replace)


  #use weight on the other

  y <- use_weight(x[[2]],rownames(x[[1]]),x[[1]])


  ## Data frame des opinions de tous

  library(dplyr)
  require(rpart)
  opinions_df <- rbind(x[[3]], y[[1]])
  opinions_df$users <- as.numeric(opinions_df$users)
  opinions_df$opinions <- as.numeric(opinions_df$opinions)


  ###Validation

  opinions_df_arrange <- arrange(opinions_df,users)

  df_validation_arrange <- arrange(df_validation,users_id)

  op_match <- merge(opinions_df_arrange,df_validation_arrange,by.x = "users",by.y = "users_id")


  validation_metrics <- cor(op_match$opinions,op_match[,3])

    #si le score est meilleur alors on garde et on passe a l'indice suivant
  if(niter==0){if((validation_metrics>abs(validation_score_fixture_weighted))){ # si le score est meilleur alors on garde et on passe a l'indice suivant 
    niter<-niter+1
    for(w in 1:length(X_replace)){
    data_cor3_opti[niter,w]<-X_replace[w]
    colnames(data_cor3_opti)[w]<-paste0("donnée de calib",w)
    }
    data_cor3_opti[niter,length(X_replace)+1]<-validation_metrics
    colnames(data_cor3_opti)[length(X_replace)+1]<-"score"
        data_cor3_opti[niter,length(X_replace)+2]<-end_time - start_time
    colnames(data_opt)[niter,length(X_replace)+2]<-"time of running"
    break
   
  }}else{
  if((validation_metrics>abs(data_cor3_opti[niter,length(X_replace)+1]))){ 
 
    niter<-niter+1
    for(w in 1:length(X_replace)){
    data_cor3_opti[niter,w]<-X_replace[w]
    colnames(data_cor3_opti)[w]<-paste0("donnée de calib",w)
    }
    data_cor3_opti[niter,length(X_replace)+1]<-validation_metrics
    colnames(data_cor3_opti)[length(X_replace)+1]<-"score"
    data_cor3_opti[niter,length(X_replace)+2]<-end_time - start_time
    colnames(data_opt)[niter,length(X_replace)+2]<-"time of running"
    break
   
  }
  }
  }
}
  


}
```

## Résultats

Les données sont enregistrées dans les data_taille"k" , par exemple :

```{r}

data_taille12
```


Maintenant nous avons calculé la moyenne du score et des temps de run des algorithmes pour pouvoir analyser les résultats et choisir la taille optimale.
Les résultats sont dans le data frame "data_results":

```{r}
data_results
```


Créons un graph pour plus de visibilité :


```{r}
library(ggplot2)
library(gridExtra)

co<-ggplot(data_results, aes(x = taille,y = `moyenne du score`)) + geom_point() + geom_line(color="red")
xy<-ggplot(data_results, aes(x = taille,y = `moyenne du temps de running`)) + geom_point() + geom_line(color="blue")

grid.arrange(co,xy, ncol=1, nrow = 2)
```

On remarque sans trop de difficulté que le maximum est atteint en 0.3 soit 30% de la taille du dfm.
De plus à partir de ce pic le temps de running devient bien trop grand, c'est pourquoi poour l'optimisation de notre algorithme nous gardons la taille à 30% du dfm.


Recommencons l'algo en gardant cette taille :


```{r, eval=FALSE}
calib_vector_opti2<-q[1,2:11]
calib_vector_opti2<-as.numeric(calib_vector_opti2)

X3<-as.numeric(rownames(dfm_fixture))[-calib_vector_opti2]

# On crée une fonction qui change le chiffre du vecteur de l'indice voulu

insert <- function(x, index, replacement, how = c("replace","left","right")) {
how <- match.arg(how)
repl <- switch (how,
replace = replacement,
left = Map("c", index, replacement),
right = Map("c", replacement, index)
)
x[index] <- repl
unlist(x)
}



X3_opti<- sample(X3,size = 0.3*length(X3))

a <- seq(1,252)
data_cor3_opti <- data.frame(a)
colnames(data_cor3_opti)[1] <- "results"
remove(a)



niter<-0

for(j in 1){
  for(i in X3_opti){
  
  X_replace<-as.numeric(insert(calib_vector_opti2,j,i))


  x <- calibrate(dfm_fixture,complet=T,X_replace)


  #use weight on the other

  y <- use_weight(x[[2]],rownames(x[[1]]),x[[1]])


  ## Data frame des opinions de tous

  library(dplyr)
  require(rpart)
  opinions_df <- rbind(x[[3]], y[[1]])
  opinions_df$users <- as.numeric(opinions_df$users)
  opinions_df$opinions <- as.numeric(opinions_df$opinions)


  ###Validation

  opinions_df_arrange <- arrange(opinions_df,users)

  df_validation_arrange <- arrange(df_validation,users_id)

  op_match <- merge(opinions_df_arrange,df_validation_arrange,by.x = "users",by.y = "users_id")


  validation_metrics <- cor(op_match$opinions,op_match[,3])

  
  if((validation_metrics>abs(validation_score_fixture_weighted))){ # si le score est meilleur alors on garde et on passe a l'indice suivant 
    niter<-niter+1
    for(w in 1:length(X_replace)){
    data_cor3_opti[niter,w]<-X_replace[w]
    colnames(data_cor3_opti)[w]<-paste0("donnée de calib",w)
    }
    data_cor3_opti[niter,length(X_replace)+1]<-validation_metrics
    colnames(data_cor3_opti)[length(X_replace)+1]<-"score"
    break
   
  }
  }
}
  
  for(j in 2:10){
  for(i in X3_opti){
  
  X_replace<-as.numeric(insert(calib_vector_opti2,j,i))


  x <- calibrate(dfm_fixture,complet=T,X_replace)


  #use weight on the other

  y <- use_weight(x[[2]],rownames(x[[1]]),x[[1]])


  ## Data frame des opinions de tous

  library(dplyr)
  require(rpart)
  opinions_df <- rbind(x[[3]], y[[1]])
  opinions_df$users <- as.numeric(opinions_df$users)
  opinions_df$opinions <- as.numeric(opinions_df$opinions)


  ###Validation

  opinions_df_arrange <- arrange(opinions_df,users)

  df_validation_arrange <- arrange(df_validation,users_id)

  op_match <- merge(opinions_df_arrange,df_validation_arrange,by.x = "users",by.y = "users_id")


  validation_metrics <- cor(op_match$opinions,op_match[,3])

    #si le score est meilleur alors on garde et on passe a l'indice suivant
  if(niter==0){if((validation_metrics>abs(validation_score_fixture_weighted))){ # si le score est meilleur alors on garde et on passe a l'indice suivant 
    niter<-niter+1
    for(w in 1:length(X_replace)){
    data_cor3_opti[niter,w]<-X_replace[w]
    colnames(data_cor3_opti)[w]<-paste0("donnée de calib",w)
    }
    data_cor3_opti[niter,length(X_replace)+1]<-validation_metrics
    colnames(data_cor3_opti)[length(X_replace)+1]<-"score"
    break
   
  }}else{
  if((validation_metrics>abs(data_cor3_opti[niter,length(X_replace)+1]))){ 
 
    niter<-niter+1
    for(w in 1:length(X_replace)){
    data_cor3_opti[niter,w]<-X_replace[w]
    colnames(data_cor3_opti)[w]<-paste0("donnée de calib",w)
    }
    data_cor3_opti[niter,length(X_replace)+1]<-validation_metrics
    colnames(data_cor3_opti)[length(X_replace)+1]<-"score"
    break
   
  }
  }
  }
}
```

Les résultats sont dans le data frame "data_cor_opt_taille_0.3":

```{r}
data_cor_opti_taille_0.3[1:3,]
```

Pour plus de visibilités faisons un graph :


```{r}
library(ggplot2)


co<-ggplot(data_cor_opti_taille_0.3[1:3,],aes(x =seq(1:3), y = score)) +geom_line()+geom_point()
co<-co+geom_hline(aes(yintercept=abs(q$validation_score[1]),linetype = "algo_10 score"), 
                color = "blue", size=0.5)+
  geom_hline(aes(yintercept=abs(validation_score_fixture_weighted), linetype = "best score"), 
                color = "green", size=0.5) +
    scale_linetype_manual(name = "limit", values = c(2, 2), guide = guide_legend(override.aes = list(color = c("blue", "green"))))



co<-co + labs(x = "vector return ", y = "score")
co
```

## Discussion / Conclusion

Cet algorithme tourne en moins de temps que l'algorithme 3 et demeure être quasi tout aussi performant, les résultats de score sont presque aussi élevés.

En arrangeant le data par ordre croissant la courbe semble décroissante mais est bien croissante;

Cela peut donc être le parfait compromis entre performance et rapidité.
